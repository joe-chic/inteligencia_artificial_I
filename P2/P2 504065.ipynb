{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2. Clasificación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para este proyecto, se desarrollan y comparan distintos modelos de clasificación para predecir si un pasajero fue transportado en la nave \"Spaceship Titanic\", basándose en la información proveída por Kaggle. Se aplican diferentes técnicas de Machine Learning, incluyendo regresión logística multinomial, análisis discriminante lineal (LDA), árboles de decisión y métodos de ensamble como bagging, random forest y boosting.\n",
    "\n",
    "#### El flujo de trabajo sigue estos pasos: <br>- Carga y exploración de datos: Se analizan los datos proporcionados, identificando valores nulos y características relevantes. <br>- Entrenamiento de modelos de clasificación: Se implementan y evalúan diversos modelos supervisados para identificar cuál ofrece el mejor rendimiento. <br>- Validación y comparación de modelos: Se utilizan técnicas de validación cruzada para medir la precisión de cada modelo y determinar su efectividad. <br>- Predicción y envío de resultados: Se genera el archivo de predicciones finales y se somete a la evaluación de Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Se cargan los datos de entrenamiento y prueba, eliminando columnas irrelevantes como PassengerId, Name y Cabin. Luego, se codifican las variables categóricas con LabelEncoder() y se normalizan los datos numéricos con StandardScaler() para asegurar que todos los modelos trabajen con valores en la misma escala.\n",
    "\n",
    "#### Igualmente, se separan los datos en X_train y y_train para el entrenamiento, y en X_val y y_val para la validación. Se utiliza un test_size=0.2, lo que significa que el 20% de los datos se reserva para validar los modelos antes de hacer predicciones finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
      "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
      "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
      "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
      "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
      "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
      "\n",
      "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
      "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
      "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
      "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
      "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
      "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
      "\n",
      "   Transported  \n",
      "0        False  \n",
      "1         True  \n",
      "2        False  \n",
      "3        False  \n",
      "4         True  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n",
      "None\n",
      "PassengerId       0\n",
      "HomePlanet      201\n",
      "CryoSleep       217\n",
      "Cabin           199\n",
      "Destination     182\n",
      "Age             179\n",
      "VIP             203\n",
      "RoomService     181\n",
      "FoodCourt       183\n",
      "ShoppingMall    208\n",
      "Spa             183\n",
      "VRDeck          188\n",
      "Name            200\n",
      "Transported       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Exploración de datos\n",
    "print(df_train.head())\n",
    "print(df_train.info())\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "# Rellenar valores nulos y convertir variables categóricas\n",
    "# Encode categorical variables\n",
    "for col in ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP']:\n",
    "    df_train[col].fillna(df_train[col].mode()[0], inplace=True)\n",
    "    df_test[col].fillna(df_test[col].mode()[0], inplace=True)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    combined_data = pd.concat([df_train[col], df_test[col]], axis=0)  # Combine train and test\n",
    "    le.fit(combined_data)  # Fit on combined data\n",
    "    \n",
    "    df_train[col] = le.transform(df_train[col])  # Transform train\n",
    "    df_test[col] = le.transform(df_test[col])    # Transform test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir 'Transported' en binario\n",
    "df_train['Transported'] = df_train['Transported'].astype(int)\n",
    "\n",
    "# Selección de características y target\n",
    "features = ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP']\n",
    "X = df_train[features]\n",
    "y = df_train['Transported']\n",
    "X_test = df_test[features]\n",
    "\n",
    "# Normalización de los datos\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# División de datos\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Se entrena un modelo de regresión logística multinomial y se evalúa su desempeño utilizando validación cruzada con 5 folds. La métrica utilizada es la accuracy, y el resultado final es el promedio de las 5 evaluaciones (np.mean(cross_val_score(...)))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística:\n",
      "Accuracy: 0.7193\n"
     ]
    }
   ],
   "source": [
    "BestModel = 0\n",
    "BestScore = 0\n",
    "\n",
    "def getBestModel(model, score, X_train, y_train):\n",
    "    global BestModel, BestScore\n",
    "\n",
    "    if(BestModel):\n",
    "       BestScore = np.mean(cross_val_score(BestModel, X_train, y_train, cv=5, scoring='accuracy'))\n",
    "\n",
    "    if(BestScore < score):\n",
    "        model.fit(X_train, y_train)\n",
    "        BestModel = model\n",
    "\n",
    "# Modelos de clasificación\n",
    "def evaluate_model(model, X_train, y_train):\n",
    "    score = np.mean(cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy'))\n",
    "\n",
    "    # Esto guardará el mejor modelo que el modelo guardará al final.\n",
    "    getBestModel(model, score, X_train, y_train)\n",
    "    \n",
    "    print(f'Accuracy: {score:.4f}')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "print(\"Regresión Logística:\")\n",
    "log_reg = evaluate_model(LogisticRegression(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Se implementa un modelo de LDA, que es útil para problemas de clasificación con datos gaussianos. Se evalúa su rendimiento de la misma forma que la regresión logística, utilizando validación cruzada con 5 folds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA:\n",
      "Accuracy: 0.7207\n"
     ]
    }
   ],
   "source": [
    "print(\"LDA:\")\n",
    "lda = evaluate_model(LinearDiscriminantAnalysis(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Se entrena un modelo basado en árboles de decisión y se evalúa utilizando la misma metodología de validación cruzada. Se compara su desempeño con los modelos anteriores para ver si es más efectivo en la clasificación de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión:\n",
      "Accuracy: 0.6415\n"
     ]
    }
   ],
   "source": [
    "print(\"Árbol de Decisión:\")\n",
    "dt = evaluate_model(DecisionTreeClassifier(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Se entrena un modelo de Random Forest, el cual utiliza una técnica de bagging al combinar múltiples árboles de decisión con el objetivo de mejorar la precisión. Se evalúa con validación cruzada y se compara su desempeño con los otros modelos. Igualmente, se repite el mismo proceso pero con Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.6424\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.7140\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "rf = evaluate_model(RandomForestClassifier(), X_train, y_train)\n",
    "\n",
    "print(\"Gradient Boosting:\")\n",
    "gb = evaluate_model(GradientBoostingClassifier(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Se utiliza el mejor modelo para predecir la variable objetivo en los datos de prueba (test.csv). Se genera el <b>archivo de salida</b> en el formato requerido por Kaggle y se obtiene la métrica de accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo submission.csv generado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Predicción en datos de prueba\n",
    "final_model = BestModel\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "\n",
    "# Generar archivo para Kaggle\n",
    "submission = pd.DataFrame({'PassengerId': df_test['PassengerId'], 'Transported': y_test_pred})\n",
    "submission['Transported'] = submission['Transported'].astype(bool)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Archivo submission.csv generado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De acuerdo con los resultados obtenidos del accuracy de cada modelo, se puede determinar que LDA fue el mejor modelo con un valor de 0.7207. Es posible que el problema sea linealmente separable y no se necesite un modelo más complejo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor modelo del conjunto fue:  LinearDiscriminantAnalysis()\n"
     ]
    }
   ],
   "source": [
    "# El mejor modelo es:\n",
    "print(\"El mejor modelo del conjunto fue: \", BestModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Código de honor:</b> Doy mi palabra de que he realizado esta actividad con integridad académica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
